# Hard Work - Извлекаем пользу из сторонних зависимостей

## Пример 1

Библиотека `Pydantic`

Использует type hints, чтобы проверять типы данных.
Библиотека используется для валидации данных, их сериализации и десериализации.

Валидация данных на Python обычно очень болезненная процедура,
и выглядит она крайне громоздко и некрасиво, со всеми этими `isinstance` и
`assert` и прочими проверками.

Казалось бы что отдельная библиотека для валидации данных будет просто
давать удобную обертку над этими проверками, но на самом деле она `Pydantic`
одна из самых запутанных бибиотек из всех что я видел.

После долгих мучений оказалось, что "ядро" проверки данных теперь вообще представляет
собой `pydantic-core` библиотеку, которая написана на `Rust`.

Что я узнал:

- `Pydantic` использует low-level библиотеку на `Rust` для валидации данных.
- Теперь примерно представляю как выглядят биндинги на `Rust` из `Python`
(ну или хотя бы где посмотреть, на них).
- Библотека использует смешанный стиль ООП и обычных функций, очень большой
уровень indirection перенаправлений, которые делаются через `build_wrapper`.
- Ради производительности приходится отказываться от чистого `Python` и
использовать более низкоуровненый язык.

Основной кусок старой версии валидирования из `Pydantic V1` выглядит так:
(довольно ужастно, если честно:)

```py

def validate_model(  # noqa: C901 (ignore complexity)
    model: Type[BaseModel], input_data: 'DictStrAny', cls: 'ModelOrDc' = None
) -> Tuple['DictStrAny', 'SetStr', Optional[ValidationError]]:
    """
    validate data against a model.
    """
    values = {}
    errors = []
    # input_data names, possibly alias
    names_used = set()
    # field names, never aliases
    fields_set = set()
    config = model.__config__
    check_extra = config.extra is not Extra.ignore
    cls_ = cls or model

    for validator in model.__pre_root_validators__:
        try:
            input_data = validator(cls_, input_data)
        except (ValueError, TypeError, AssertionError) as exc:
            return {}, set(), ValidationError([ErrorWrapper(exc, loc=ROOT_KEY)], cls_)

    for name, field in model.__fields__.items():
        value = input_data.get(field.alias, _missing)
        using_name = False
        if value is _missing and config.allow_population_by_field_name and field.alt_alias:
            value = input_data.get(field.name, _missing)
            using_name = True

        if value is _missing:
            if field.required:
                errors.append(ErrorWrapper(MissingError(), loc=field.alias))
                continue

            value = field.get_default()

            if not config.validate_all and not field.validate_always:
                values[name] = value
                continue
        else:
            fields_set.add(name)
            if check_extra:
                names_used.add(field.name if using_name else field.alias)

        v_, errors_ = field.validate(value, values, loc=field.alias, cls=cls_)
        if isinstance(errors_, ErrorWrapper):
            errors.append(errors_)
        elif isinstance(errors_, list):
            errors.extend(errors_)
        else:
            values[name] = v_
    if check_extra:
        if isinstance(input_data, GetterDict):
            extra = input_data.extra_keys() - names_used
        else:
            extra = input_data.keys() - names_used
        if extra:
            fields_set |= extra
            if config.extra is Extra.allow:
                for f in extra:
                    values[f] = input_data[f]
            else:
                for f in sorted(extra):
                    errors.append(ErrorWrapper(ExtraError(), loc=f))

    for skip_on_failure, validator in model.__post_root_validators__:
        if skip_on_failure and errors:
            continue
        try:
            values = validator(cls_, values)
        except (ValueError, TypeError, AssertionError) as exc:
            errors.append(ErrorWrapper(exc, loc=ROOT_KEY))

    if errors:
        return values, fields_set, ValidationError(errors, cls_)
    else:
        return values, fields_set, None
```

## Пример 2

Библиотека `clickhouse-driver`
Предназначена для взаимодействия с `ClickHouse` из `Python`.
С ней было проще разобраться, потому что она написала на мой вкус
гораздо более прямолинейно, чем `Pydantic`.

Было интересно как именно происходит общение непосредственно с `ClickHouse`,
оказалось, что всё довольно прямолинейно: создаётся сокет и устанавливается
TCP соединение. Ядро этого "общения" можно выразить в следующем коде:

```py
# clickhouse_driver/buffered_socket.py

class BufferedSocketBase(object):
    def read(self, n):
        # Reads n bytes from the socket
        return self.socket.recv(n)
    
    def write(self, data):
        # Writes data to the socket
        return self.socket.send(data)
```

Кроме того проект использует `Cython` для ускорения работы сериализации и
десериализации данных.


```
# Cython implementation for integer columns
cdef class IntColumn(Column):
    cdef readonly uint64_t max_value
    cdef readonly uint64_t min_value
    
    cpdef write_items(self, items, buf):
        cdef uint64_t value
        # Fast C-level loop for writing integers
        for value in items:
            write_varint(value, buf)
```

Что я узнал:

- `Cython` позволяет писать условный `C` код на `Python`. Я на самом деле
забыл, что он вообще существует, и что это вполне альтернатива для того,
чтобы использовать совсем другой язык для производительных частей библиотеки.
- Низкоуровные взаимодействия с БД всё равно так или иначе сводятся
к базе: создание сокета, установление соединения, TCP. Значит написать
подобное своё хотя может быть сложно, но концептуально понятно.


## Пример 3

Библиотека `pytest`
(в следующий раз стоит выбрать что-то попроще)

`pytest` использует свой собственный модуль для поиска тестов, с тонкой настройкой
для поиска и запуска тестов. Для этого используется модуль `pathlib.py`.
Практически не использует ООП, имеет короткие и понятные функции.
Пример из того же `pathlib.py`:


```py
# pathlib.py

def extract_suffixes(iter: Iterable[os.DirEntry[str]], prefix: str) -> Iterator[str]:
    """Return the parts of the paths following the prefix.

    :param iter: Iterator over path names.
    :param prefix: Expected prefix of the path names.
    """
    p_len = len(prefix)
    for entry in iter:
        yield entry.name[p_len:]


def find_suffixes(root: Path, prefix: str) -> Iterator[str]:
    """Combine find_prefixes and extract_suffixes."""
    return extract_suffixes(find_prefixed(root, prefix), prefix)


def parse_num(maybe_num: str) -> int:
    """Parse number path suffixes, returns -1 on error."""
    try:
        return int(maybe_num)
    except ValueError:
        return -1
```

Что я узнал:

- `pytest` на самом деле написал 100% на `Python` и в отличие от
предыдущих примеров он не использует никаких сторонних инструментов для
ускорения производительности. При это остаётся довольной быстрым.
- `pytest` в основном написан в имеративном стиле, на 90% используются
только функции и редкие классы скорее как небольшие модули или Enum'ы.

## Выводы

Это правда что в начале я воспринимал сторонние библиотеки как черный ящик,
просто как данность, волшебный инструмент, который я использую, не вдаваясь в
подробности. И будто-бы это нормальная ситуация, и так и нужно, в конце концов
её написали более умные и опытные люди, и они точно знают что делают.

Но потом я понял, что это не так.

Во-первых, даже умные и опытные люди могут допускать ошибки, недопонимания, security уязвимости, и т.д.
Во-вторых, обычно в основе всех этих библиотек находится довольно простая
идея, и если докопаться до "ядра", то её можно относитлеьно легко понять.
Но что делает эти библиотеки популярными, это то как вокруг этой идеи
есть множество дополнительных утилит, тестов и просто архитектурных решений 
для дальнейшего расширения. Наверное, в основном это и делает многие из
них сложными для понимания, так как экосистема вокруг них развивалась долго
и постепенно обросла слоем абстракций и сложности.

