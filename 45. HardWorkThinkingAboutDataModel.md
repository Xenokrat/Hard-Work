# Hard Work - Как правильно думать над моделью данных

## Пример 1

Предположим, у нас есть мониторинг для работы парсера.
Парсер собирает информацию с приложений доставки на 

1. Разных площадках
2. Разных странах

Для мониторинга отслеживается сколько магазинов было собрано на каждой площадке в каждой стране, а также количество проходов парсера на каждый магазин.

Стандартная модель данных представляла собой следующее отношение:

- Дата
- Площадка
- Количество собранных магазинов vs. общее количество магазинов
- Количество проходов парсера на площадку

Примерная схема:

```JSON
{
    "2024-01-01": { "app1": [280, 300], "app2": [300, 300] },
    "2024-01-02": { "app1": [270, 300], "app2": [220, 300] },
    "2024-01-03": { "app1": [290, 300], "app2": [270, 300] },
}
```

Такая модель получалась из сырых (необработанных) данных из БД при запросе BI.

У такой модели есть 2 проблемы:

- Отсутствие гибкости, например из модели выше нельзя узнать статистику по различным странам
- Медленная работа при запросе данных (т.к. их нужно обработать перед выводом).

Новая модель данных, к которой я пришел недавно, заключается в следующем:

Схема: сырые данные -> промежуточная модель, данные которой хранятся в БД -> визуализация.

Пример 2 моделей:

- Модель дата - страна - статистика на площадки по стране
- Модель дата - площадка - статистика на страны по площадке

Такое использование без сомнения дублирует данные, однако позволяет пользователю обращаться к уже пред-агрегированным данным, вместо того, чтобы обрабатывать то что фактически лежит в БД и
при этом значительно повышает скорость работы. Также поддерживается возможность добавлять новые пред-агрегированные модели по желанию пользователя.

## Пример 2

Пример из дипломного проекта по представлению автопарка на `Django`.

Для характеристики поездок водителей используется следующая структура:

Словарь:

- авто: значение id
- водитель: id_водителя
- путь: [Point1, Point2, ...]

Структура Point:

```python
@dataclass
class Point:
    timestamp: datetime
    latitude: float
    longitude: float
```

Такого набора данных достаточно, чтобы фактически полностью характеризовать любую поездку поездку.
Из такого набора данных можно расчитать также примерную скорость авто, общее время в пути, время остановок и т.д.
Однако, при таком сценарии в БД хранится огромное количество записей по `Point` и использовать такие вот "сырые" данные для работы приложения может быть неэффективно.
Для решения рода проблем, возникающих из-за формата хранения это информации, можно создать дополнительные сущености, например:

```python
@dataclass
class RideStat:
    ride_id: int
    driver_id: int
    total_time: timedelta
    total_mileage: int
    average_speed: int
    average_idle_time: timedelta
```

При добавлении новой записи о поездке можно автоматически создавать и записывать в БД дополнительную информацию по статистике поездки.
Допустим, если аналитику нужна подобная информация о поездке (расчитываем, что в 95% случаев, ему будет достаточно информации из класса `RideStat`), его запросы будут создавать заначительно меньше нагрузки на приложение в целом (не забываем при этом, что в противном случае нужно не только извлечь все точки, но и пересчитать метрики поездки).

## Пример 3

Схожую с примером 1 модель можно применить также для бота (в программе `Slack`), которого мы используем для быстрого доступа к статистике работы приложений.
Здесь это может быть даже удобнее, так как при запуске программы с ботом на сервере, можно подгружать в память ту часть данных, которая не обновляется в реальном времени (т.е. данные за вчера например).
(т.е. фактически, это реализовано как кэширование).

```python
# Примитивный механизм для кэша
def get_ttl_hash(seconds=43200) -> int:
    return time.time() // 43200

@cache
def get_prod_default_apps(ttl_hash=None) -> set[str]:
    del ttl_hash
    query = """
        Text of the query
    """
    default_platform = db_client.execute(query)
    return {platform_[0] for platform_ in default_platform}
```

Таки кэшированные данные затем можно использовать в других функциях, которым например, требуется список из дефолтных приложений, как в примере выше.
Таким образом мы значительно можем повысить скорость работы приложения.
Недостатком может быть конечно, что в случае когда все функции для возврата данных менеджеру в чат приложения зависят от наличия той или иной информации из какой-то другой функции, то поддерживать такую систему становится значительно сложнее.

## Выводы

Идея с информационной избыточностью довольно близка мне, так как часто приходится подготавливать пайплайны для визуализации данных в BI-системах.
И в таких случаях зачастую очень неэффективно хранить информацию только в каком-то одном виде и гораздо лучше подготавливать данные заранее для 
надлежащего представления в визуализации. Причем данные могут быть одни и те же, но формат их представления может отличаться значительно, и по рукой всегда проще иметь уже заготовленное представление.
Поэтому различного рода вью и материализованные вью, а также кэширование данных широко используются при работе с BI-системами.
При этом СУБД часто могут взять на себя роль по синхронизации данных за счет собственных механизмоов, таких как транзакции.
При этом идея использования такой избыточности непосредственно в программе (как описано в данном занятии) теперь хорошо соотносится с моим опытом работы с СУБД.
Опять таки, как и было сказано в занятии, ценой удобство для пользователя является потенциальная сложность в поддержке такой системы, с "дублированием" информации.
